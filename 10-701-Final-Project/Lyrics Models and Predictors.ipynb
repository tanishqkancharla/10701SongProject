{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import scipy.io as sio\n",
    "import hdf5_getters\n",
    "from pandas import read_hdf\n",
    "# from musixmatch import Musixmatch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF = pd.read_pickle(\"finalLyricsData\")\n",
    "lyricsTokenDF = pd.read_pickle(\"tokenizedDF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF_withall = newDF.drop(['track_id','musixIndex','lyrics','danceability', 'energy'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)\n",
      "[4.82915013 1.8005586  1.68018689 1.52084247 1.23700455 1.15892881\n",
      " 1.02707289 0.94627583 0.91706778 0.83070844 0.71974066 0.69240375\n",
      " 0.59777826 0.54300777 0.50399966 0.47333758 0.42491719 0.4191543\n",
      " 0.39359048 0.38186649 0.37619093 0.35462944 0.32753269 0.3115587\n",
      " 0.29511247 0.29047379 0.28092188 0.27094604 0.2585423  0.25515465\n",
      " 0.24670075 0.24146913 0.23573383 0.23178757 0.2292323  0.22594367\n",
      " 0.21264209 0.21080814 0.20582673 0.20047935 0.19849956 0.19482042\n",
      " 0.18637202 0.18536258 0.17994043 0.174802   0.1706716  0.16921437\n",
      " 0.166289   0.16138151 0.15826733 0.15433896 0.15254136 0.14968928\n",
      " 0.1476642  0.14504778 0.14223432 0.14102439 0.13626861 0.13441938\n",
      " 0.1316517  0.13085429 0.12865335 0.12641026 0.12556813 0.12312521\n",
      " 0.12130142 0.12020214 0.11999131 0.11692817 0.11581194 0.11488138\n",
      " 0.11248397 0.11153199 0.11044837 0.10942352 0.10743996 0.10602839\n",
      " 0.10516303 0.10462625 0.10378938 0.10108605 0.0998109  0.09932772\n",
      " 0.09768602 0.09692586 0.09580783 0.0948337  0.09424101 0.09255405\n",
      " 0.09210037 0.09135138 0.0895322  0.08889448 0.08880059 0.08770731\n",
      " 0.08663048 0.08572301 0.08474912 0.08406366]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "justLyrics = np.transpose(lyricsTokenDF.drop(columns=['y']))\n",
    "pca = PCA(n_components=100)\n",
    "print(pca.fit(justLyrics))\n",
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08952436 0.03337934 0.03114785 0.02819387 0.02293199 0.0214846\n",
      " 0.01904021 0.01754237 0.0170009  0.01539994 0.01334279 0.01283601\n",
      " 0.01108181 0.01006646 0.00934331 0.00877489 0.00787725 0.00777042\n",
      " 0.00729651 0.00707917 0.00697395 0.00657424 0.00607191 0.00577578\n",
      " 0.00547089 0.0053849  0.00520782 0.00502289 0.00479294 0.00473014\n",
      " 0.00457342 0.00447643 0.00437011 0.00429695 0.00424958 0.00418862\n",
      " 0.00394203 0.00390803 0.00381568 0.00371655 0.00367985 0.00361164\n",
      " 0.00345503 0.00343631 0.00333579 0.00324054 0.00316397 0.00313695\n",
      " 0.00308272 0.00299174 0.00293401 0.00286119 0.00282786 0.00277499\n",
      " 0.00273745 0.00268894 0.00263679 0.00261436 0.00252619 0.00249191\n",
      " 0.0024406  0.00242582 0.00238502 0.00234343 0.00232782 0.00228254\n",
      " 0.00224873 0.00222835 0.00222444 0.00216765 0.00214696 0.00212971\n",
      " 0.00208526 0.00206762 0.00204753 0.00202853 0.00199176 0.00196559\n",
      " 0.00194955 0.0019396  0.00192408 0.00187397 0.00185033 0.00184137\n",
      " 0.00181094 0.00179684 0.00177612 0.00175806 0.00174707 0.0017158\n",
      " 0.00170739 0.0016935  0.00165978 0.00164795 0.00164621 0.00162595\n",
      " 0.00160598 0.00158916 0.00157111 0.0015584 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2326, 100)\n",
      "(2326, 4593)\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "plt.plot(range(len(pca.explained_variance_)), pca.explained_variance_)\n",
    "# print(np.sum(pca.explained_variance_))\n",
    "# print(np.sum(pca.explained_variance_[:100]))\n",
    "plt.show()\n",
    "#100 componenets explain 62.38 variance and total variance is 102.07\n",
    "pcaComponents = np.transpose(pca.components_)\n",
    "print(pcaComponents.shape)\n",
    "print(lyricsTokenDF.shape)\n",
    "# lyricsTokenDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157.71871498534404\n",
      "247.41530527870904\n",
      "161.6698140407824\n",
      "601.6565260508681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "##Testing and training losses:\n",
    "##Default adaboost regressor with square loss trained with 100 pca components:\n",
    "####Train MSE: 139.9\n",
    "####Train AMSE: 269.4\n",
    "####Test MSE: 158.06\n",
    "####Test AMSE: 963.018\n",
    "##Default adaboost regressor with linear loss trained with 100 pca components:\n",
    "####Train MSE: 173.77\n",
    "####Train AMSE: 233.12\n",
    "####Test MSE: 212.3\n",
    "####Test AMSE: 980.94\n",
    "##Default adaboost regressor with linear loss trained with original lyrics dataframe:\n",
    "####Train MSE: 283.25\n",
    "####Train AMSE: 401.85\n",
    "####Test MSE: 287.18\n",
    "####Test AMSE: 960.79\n",
    "##Default adaboost regressor with square loss trained with original lyrics dataframe:\n",
    "####Train MSE: 289.30\n",
    "####Train AMSE: 356.99\n",
    "####Test MSE: 323.95\n",
    "####Test AMSE: 1002.27\n",
    "##Default adaboost regressor with square loss trained with newDF_withall:\n",
    "####Train MSE: 109.02\n",
    "####Train AMSE: 208.60\n",
    "####Test MSE: 142.98\n",
    "####Test AMSE: 1020.71\n",
    "##Default adaboost regressor with linear loss trained with newDF_withall:\n",
    "####Train MSE: 157.71\n",
    "####Train AMSE: 247.41\n",
    "####Test MSE: 161.67\n",
    "####Test AMSE: 601.66\n",
    "abr = AdaBoostRegressor(loss='linear')\n",
    "# print(newDF_withall.columns.values)\n",
    "x_train, x_test, y_train, y_test = train_test_split(newDF_withall.drop(columns=['year']), newDF_withall['year'], test_size=0.2)\n",
    "abr.fit(x_train, y_train)\n",
    "y_trainpred = abr.predict(x_train)\n",
    "print(mean_squared_error(y_train,y_trainpred))\n",
    "print(adjusted_mean_squared_error(y_train,y_trainpred))\n",
    "y_testpred = abr.predict(x_test)\n",
    "print(mean_squared_error(y_test,y_testpred))\n",
    "print(adjusted_mean_squared_error(y_test,y_testpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Constructing a weight-adjusted loss function\n",
    "from collections import Counter\n",
    "counts = Counter(newDF_withall['year']).items()\n",
    "countDataFrame = pd.DataFrame(data=counts)\n",
    "countDataFrame.sort_values(0,inplace=True)\n",
    "# print(countDataFrame)\n",
    "plt.plot(countDataFrame[0], countDataFrame[1])\n",
    "plt.show()\n",
    "weights = [1/countDataFrame]\n",
    "\n",
    "\n",
    "# def find_weight(y_true):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288.50171969045573\n",
      "1997 143.8310404127257\n"
     ]
    }
   ],
   "source": [
    "############## NAIVE REGRESSION MODEL (predicting 1997 for every one is the best) ###################\n",
    "bestPred = 0\n",
    "bestErr = 10000000000\n",
    "numPoints = len(newDF['year'])\n",
    "for tPred in range(1980,2010):\n",
    "    tempErr = mean_squared_error(np.repeat(tPred,numPoints),newDF['year'])\n",
    "    if tempErr < bestErr:\n",
    "        bestErr = tempErr\n",
    "        bestPred = tPred\n",
    "print(adjusted_mean_squared_error(np.repeat(tPred,numPoints),newDF['year']))\n",
    "print(bestPred, bestErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## SET UP TOKEN VECTORIZER ##################\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "vectorizer_count = CountVectorizer(analyzer = \"word\", preprocessor = None, \n",
    "                                   stop_words='english', min_df=8, max_df=0.5, tokenizer=tokenizer.tokenize) \n",
    "vectorizer_tfid = TfidfVectorizer(max_df=0.5,min_df=8,stop_words='english')\n",
    "\n",
    "# include 1-grams and 2-grams\n",
    "#vectorizer.set_params(ngram_range=(1, 2))\n",
    "\n",
    "train_data_features_tfid = vectorizer_tfid.fit_transform(newDF[\"lyrics\"])\n",
    "train_data_features_count = vectorizer_count.fit_transform(newDF[\"lyrics\"])\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "#train_data_features = train_data_features.toarray()\n",
    "# see final the clean data\n",
    "#print (train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "######### FOR SOME REASON PCA DOESN'T WORK WHEN USING TfidfVectorizer BUT IT WORKED WITH CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "maxComp = min(train_data_features_tfid.shape)\n",
    "#pca = PCA(n_components=maxComp-1)\n",
    "svd = TruncatedSVD(n_components=maxComp-1)\n",
    "#pca.fit(train_data_features)\n",
    "#PCA(copy=True, iterated_power='auto', n_components=2, random_state=None, svd_solver='auto', tol=0.0, whiten=False)\n",
    "svd.fit(train_data_features_tfid)\n",
    "#pca.fit(train_data_features_count)\n",
    "#plt.figure()\n",
    "#plt.scatter(np.arange(40), svd.explained_variance_ratio_[0:40])\n",
    "#plt.figure(1)\n",
    "#plt.scatter(np.arange(x.shape[0])[0:40], pca.explained_variance_ratio_[0:40])\n",
    "# could maybe do ten?\n",
    "\n",
    "def select_n_components(var_ratio, goal_var: float):\n",
    "    # Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "    \n",
    "    # Set initial number of features\n",
    "    n_components = 0\n",
    "    \n",
    "    # For the explained variance of each feature:\n",
    "    for explained_variance in var_ratio:\n",
    "        \n",
    "        # Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "        \n",
    "        # Add one to the number of components\n",
    "        n_components += 1\n",
    "        \n",
    "        # If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "            # End the loop\n",
    "            break\n",
    "            \n",
    "    # Return the number of components\n",
    "    return n_components\n",
    "\n",
    "print(select_n_components(svd.explained_variance_ratio_, 0.6)) # \"Multivariate Analysis\" by Hair et al (2012). the acceptable variance explained in factor analysis for a construct to be valid is sixty per cent.\n",
    "print(select_n_components(svd.explained_variance_ratio_, 0.25))\n",
    "tTrans = svd.transform(train_data_features_tfid)\n",
    "newLyricsTransform = pd.DataFrame(tTrans).drop(np.arange(58,len(tTrans[0])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2326, 92)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### NEW DATAFRAME WITH ALL INFO FROM COMPRESSED LYRICS (25% VARIANCE EXPLAINED) AND MUSIC FEATURES\n",
    "newDF_withall = newDF.drop(['track_id','musixIndex','lyrics','danceability', 'energy'],axis=1)\n",
    "newDF_withall = newDF_withall.set_index(np.arange(newDF_withall.shape[0]))\n",
    "newDF_withall = pd.concat([newDF_withall, newLyricsTransform], axis=1, sort=False)\n",
    "newDF_withall.fillna(newDF_withall.mean(), inplace=True)\n",
    "\n",
    "newDF_withall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADABOOST REGRESSOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### COULD TRY RUNNING REGRESSION MODELS ON BOTH THE LYRICS AND MUSIC FEATURES SEPARATELY\n",
    "############### (SHOULDN'T COMPRESS LYRICS AS MUCH AS IN MAIN DATAFRAME (MAYBE USE 60% OR SOMETHING))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'n_components')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "################# FITTING MIXTURE MODEL FOR WHOLE DATA (GAUSSIAN MIXTURE)\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "n_components = np.arange(1, 40)\n",
    "models = [GaussianMixture(n, covariance_type='full', random_state=0).fit(newDF_withall.drop('year',axis=1))\n",
    "          for n in n_components]\n",
    "plt.figure(0)\n",
    "plt.plot(n_components, [m.bic(newDF_withall.drop('year',axis=1)) for m in models], label='BIC')\n",
    "plt.plot(n_components, [m.aic(newDF_withall.drop('year',axis=1)) for m in models], label='AIC')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('n_components')\n",
    "\n",
    "############## SEEMS LIKE 9 COMPONENTS MAY BE THE MOVE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134.8150372798868"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################ CLUSTER TO FIT IDEAL 9 COMPONENTS AND THEN FIT MODEL WITH THOSE COMPONENTS\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "gMM = GaussianMixture(n_components = 9, covariance_type='full', random_state=0)\n",
    "thePreds1 = gMM.fit_predict(newDF_withall.drop('year',axis=1))\n",
    "\n",
    "clusterDF1 = pd.DataFrame({\"cluster\": thePreds1, \"year\":newDF_withall['year']})\n",
    "x_train_clust1, x_test_clust1, y_train_clust1, y_test_clust1 = train_test_split(clusterDF1.drop('year',axis=1), clusterDF1['year'], test_size=0.2)\n",
    "\n",
    "from sklearn import tree\n",
    "treeMod = tree.DecisionTreeRegressor()\n",
    "treeMod.fit(x_train_clust1, y_train_clust1)\n",
    "\n",
    "mean_squared_error(y_test_clust1,treeMod.predict(x_test_clust1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_mean_squared_error(y_true, y_predict):\n",
    "    #determine MSE for each decade and then take the average\n",
    "    #this helps to adjust for the fact that our dataset is heavily concentrated in 2000\n",
    "    (lower, upper) = (min(y_true), max(y_true))\n",
    "    y_true = np.array(y_true)\n",
    "    y_predict = np.array(y_predict)\n",
    "    np.reshape(y_true, (len(y_true)))\n",
    "    np.reshape(y_predict, (len(y_predict)))\n",
    "    decades = range(int(np.floor(lower/10)*10), int(np.floor(upper)), 10)\n",
    "    mse = []\n",
    "    for decade in decades:\n",
    "        filter = [a >= decade and a < decade+10 for a in y_true]\n",
    "        if(len(y_true[filter]) > 0):\n",
    "            mse.append(mean_squared_error(y_true[filter], y_predict[filter]))\n",
    "    return np.average(mse)\n",
    "\n",
    "# adjusted_mean_squared_error(y_train, regRidge.predict(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge train:  197.44975832661282 Ridge test:  1172.3354272425797\n",
      "Lasso train:  1234.8480466533938 Lass test:  1114.368225760118\n"
     ]
    }
   ],
   "source": [
    "################ TRAIN MODELS\n",
    "regRidge = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0], cv=3)\n",
    "regRidge.fit(x_train, y_train)\n",
    "trainMSE_ridge = adjusted_mean_squared_error(y_train, regRidge.predict(x_train))\n",
    "testMSE_ridge = adjusted_mean_squared_error(y_test, regRidge.predict(x_test))\n",
    "\n",
    "regLasso = linear_model.Lasso(alpha=0.1)\n",
    "regLasso.fit(x_train, y_train)\n",
    "trainMSE_lasso = adjusted_mean_squared_error(y_train, regLasso.predict(x_train))\n",
    "testMSE_lasso = adjusted_mean_squared_error(y_test, regLasso.predict(x_test))\n",
    "\n",
    "print(\"Ridge train: \", trainMSE_ridge, \"Ridge test: \", testMSE_ridge)\n",
    "print(\"Lasso train: \", trainMSE_lasso, \"Lass test: \", testMSE_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regRidge.predict(x_train)\n",
    "(min(y_train), max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144.91047823764416\n",
      "182.26448501943278\n"
     ]
    }
   ],
   "source": [
    "############## Dimension Reduction for bag of words (PCA)\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "clf = SVR(gamma='scale') #SVR(gamma='scale', C=1.0, epsilon=0.2)\n",
    "clf.fit(x_train, y_train)\n",
    "print(mean_squared_error(y_train, clf.predict(x_train)))\n",
    "print(mean_squared_error(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1473"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_train>1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1860/1860 [==============================] - 3s 1ms/step - loss: 2401564.5747\n",
      "Epoch 2/10\n",
      "1860/1860 [==============================] - 2s 1ms/step - loss: 761037.8224\n",
      "Epoch 3/10\n",
      "1860/1860 [==============================] - 2s 1ms/step - loss: 405988.2618\n",
      "Epoch 4/10\n",
      "1860/1860 [==============================] - 2s 1ms/step - loss: 209482.3632\n",
      "Epoch 5/10\n",
      "1860/1860 [==============================] - 2s 1ms/step - loss: 104899.6081\n",
      "Epoch 6/10\n",
      "1860/1860 [==============================] - 2s 1ms/step - loss: 57705.9515\n",
      "Epoch 7/10\n",
      "1860/1860 [==============================] - 2s 1ms/step - loss: 36280.3551\n",
      "Epoch 8/10\n",
      "1860/1860 [==============================] - 2s 1ms/step - loss: 24196.5698\n",
      "Epoch 9/10\n",
      "1860/1860 [==============================] - 2s 1ms/step - loss: 17942.2961\n",
      "Epoch 10/10\n",
      "1860/1860 [==============================] - 2s 1ms/step - loss: 16119.1963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1946.5184],\n",
       "       [1744.9718],\n",
       "       [1990.0282],\n",
       "       ...,\n",
       "       [1919.7136],\n",
       "       [1989.7479],\n",
       "       [2019.7651]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "nFeat = x_train.shape[1]\n",
    "model.add(Dense(1000, input_dim=nFeat, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(500, input_dim=nFeat, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(100, input_dim=nFeat, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "#print(mean_squared_error(y_train, model.predict(x_train)))\n",
    "#print(mean_squared_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1946.5184]\n",
      " [1744.9718]\n",
      " [1990.0282]\n",
      " ...\n",
      " [1919.7136]\n",
      " [1989.7479]\n",
      " [2019.7651]]\n",
      "14615.4120401605\n",
      "381550.84935210913\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(x_train))\n",
    "print(mean_squared_error(y_train, model.predict(x_train)))\n",
    "print(mean_squared_error(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TOKENIZE TESTING DATA AND THEN MAKE PREDICTIONS\n",
    "#X_test_vect = vectorizer.transform(x_test)\n",
    "\n",
    "predicted = theModel.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDataFrame = newDF.drop([\"track_id\",\"musixIndex\", \"lyrics\"],axis=1)\n",
    "finalDataFrame = finalDataFrame.set_index(np.arange(newDF.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_hotttnesss</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration</th>\n",
       "      <th>end_of_fade_in</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>song_hotttnesss</th>\n",
       "      <th>tempo</th>\n",
       "      <th>...</th>\n",
       "      <th>615</th>\n",
       "      <th>616</th>\n",
       "      <th>617</th>\n",
       "      <th>618</th>\n",
       "      <th>619</th>\n",
       "      <th>620</th>\n",
       "      <th>621</th>\n",
       "      <th>622</th>\n",
       "      <th>623</th>\n",
       "      <th>624</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.434860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.99546</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11.061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475638</td>\n",
       "      <td>80.084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071945</td>\n",
       "      <td>-0.257032</td>\n",
       "      <td>-0.196539</td>\n",
       "      <td>0.293499</td>\n",
       "      <td>-0.090210</td>\n",
       "      <td>-0.008033</td>\n",
       "      <td>-0.063375</td>\n",
       "      <td>-0.091004</td>\n",
       "      <td>-0.023878</td>\n",
       "      <td>-0.152406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.334520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.63057</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-5.795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106758</td>\n",
       "      <td>-0.030016</td>\n",
       "      <td>-0.204888</td>\n",
       "      <td>-0.081121</td>\n",
       "      <td>-0.086589</td>\n",
       "      <td>0.024623</td>\n",
       "      <td>0.020169</td>\n",
       "      <td>-0.202278</td>\n",
       "      <td>-0.147184</td>\n",
       "      <td>0.137444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.539245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.84200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.788388</td>\n",
       "      <td>92.897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041058</td>\n",
       "      <td>-0.032635</td>\n",
       "      <td>-0.087466</td>\n",
       "      <td>-0.047189</td>\n",
       "      <td>-0.054714</td>\n",
       "      <td>0.040012</td>\n",
       "      <td>-0.166939</td>\n",
       "      <td>0.152990</td>\n",
       "      <td>0.318973</td>\n",
       "      <td>-0.200929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.592439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218.90567</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.681092</td>\n",
       "      <td>157.715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029487</td>\n",
       "      <td>-0.151878</td>\n",
       "      <td>0.157312</td>\n",
       "      <td>-0.086829</td>\n",
       "      <td>0.024325</td>\n",
       "      <td>0.144210</td>\n",
       "      <td>-0.169575</td>\n",
       "      <td>0.266788</td>\n",
       "      <td>0.334551</td>\n",
       "      <td>0.293172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.455559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283.48036</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.687874</td>\n",
       "      <td>84.992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050722</td>\n",
       "      <td>-0.062439</td>\n",
       "      <td>0.067779</td>\n",
       "      <td>-0.073572</td>\n",
       "      <td>-0.116098</td>\n",
       "      <td>0.100691</td>\n",
       "      <td>0.049677</td>\n",
       "      <td>0.043782</td>\n",
       "      <td>-0.046400</td>\n",
       "      <td>0.104637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.791143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.95302</td>\n",
       "      <td>3.245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.872229</td>\n",
       "      <td>105.095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145900</td>\n",
       "      <td>0.100286</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.013310</td>\n",
       "      <td>-0.072774</td>\n",
       "      <td>0.088626</td>\n",
       "      <td>0.122783</td>\n",
       "      <td>0.183677</td>\n",
       "      <td>-0.259670</td>\n",
       "      <td>-0.108917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.578302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.93179</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-15.433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596841</td>\n",
       "      <td>100.042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136758</td>\n",
       "      <td>0.125596</td>\n",
       "      <td>-0.089743</td>\n",
       "      <td>0.011098</td>\n",
       "      <td>-0.007018</td>\n",
       "      <td>-0.029027</td>\n",
       "      <td>-0.111789</td>\n",
       "      <td>-0.012239</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>-0.090266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.481656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.96689</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-20.172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046465</td>\n",
       "      <td>0.089363</td>\n",
       "      <td>0.180623</td>\n",
       "      <td>-0.047567</td>\n",
       "      <td>0.139121</td>\n",
       "      <td>-0.042693</td>\n",
       "      <td>-0.115458</td>\n",
       "      <td>0.064821</td>\n",
       "      <td>-0.090276</td>\n",
       "      <td>-0.035782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.411546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319.84281</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624834</td>\n",
       "      <td>92.971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151781</td>\n",
       "      <td>0.191513</td>\n",
       "      <td>0.166944</td>\n",
       "      <td>0.123518</td>\n",
       "      <td>-0.274576</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.168240</td>\n",
       "      <td>0.077520</td>\n",
       "      <td>-0.122940</td>\n",
       "      <td>-0.146868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.459660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258.16771</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-5.193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.427447</td>\n",
       "      <td>117.936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098311</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>-0.108096</td>\n",
       "      <td>-0.147739</td>\n",
       "      <td>-0.129239</td>\n",
       "      <td>-0.021527</td>\n",
       "      <td>-0.209052</td>\n",
       "      <td>-0.185252</td>\n",
       "      <td>-0.074520</td>\n",
       "      <td>0.110015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.405178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461.71383</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094475</td>\n",
       "      <td>0.053965</td>\n",
       "      <td>-0.033818</td>\n",
       "      <td>-0.077687</td>\n",
       "      <td>-0.319165</td>\n",
       "      <td>-0.032971</td>\n",
       "      <td>0.028166</td>\n",
       "      <td>0.079650</td>\n",
       "      <td>0.219870</td>\n",
       "      <td>0.121621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.387912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253.90975</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-5.548</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.576400</td>\n",
       "      <td>136.945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017765</td>\n",
       "      <td>-0.139854</td>\n",
       "      <td>0.175820</td>\n",
       "      <td>-0.058053</td>\n",
       "      <td>0.095490</td>\n",
       "      <td>0.234333</td>\n",
       "      <td>0.170369</td>\n",
       "      <td>-0.224653</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>-0.122940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.683658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.21751</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.057</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.476435</td>\n",
       "      <td>188.910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300609</td>\n",
       "      <td>0.270010</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.095163</td>\n",
       "      <td>0.121558</td>\n",
       "      <td>0.195638</td>\n",
       "      <td>-0.283264</td>\n",
       "      <td>-0.110193</td>\n",
       "      <td>0.283781</td>\n",
       "      <td>-0.111221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.405967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186.20036</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-13.845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.299877</td>\n",
       "      <td>156.285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077810</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>0.119301</td>\n",
       "      <td>0.068917</td>\n",
       "      <td>0.030684</td>\n",
       "      <td>0.046892</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>-0.127559</td>\n",
       "      <td>-0.087777</td>\n",
       "      <td>0.099649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.718891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>311.27465</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139.950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099829</td>\n",
       "      <td>0.175729</td>\n",
       "      <td>-0.195131</td>\n",
       "      <td>0.220543</td>\n",
       "      <td>-0.027311</td>\n",
       "      <td>0.083499</td>\n",
       "      <td>0.254968</td>\n",
       "      <td>-0.269290</td>\n",
       "      <td>-0.458477</td>\n",
       "      <td>-0.044848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.446072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>286.58893</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-4.627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536789</td>\n",
       "      <td>97.265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007088</td>\n",
       "      <td>0.132718</td>\n",
       "      <td>0.062078</td>\n",
       "      <td>0.110979</td>\n",
       "      <td>-0.004852</td>\n",
       "      <td>-0.088944</td>\n",
       "      <td>-0.118659</td>\n",
       "      <td>0.065909</td>\n",
       "      <td>-0.041021</td>\n",
       "      <td>-0.141186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.579989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.23138</td>\n",
       "      <td>12.452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685351</td>\n",
       "      <td>87.899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286286</td>\n",
       "      <td>0.010979</td>\n",
       "      <td>0.161341</td>\n",
       "      <td>-0.149894</td>\n",
       "      <td>-0.093640</td>\n",
       "      <td>0.197458</td>\n",
       "      <td>-0.079653</td>\n",
       "      <td>-0.095868</td>\n",
       "      <td>0.160691</td>\n",
       "      <td>-0.055320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.417413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.76036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.594359</td>\n",
       "      <td>163.086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139836</td>\n",
       "      <td>-0.029471</td>\n",
       "      <td>-0.012448</td>\n",
       "      <td>-0.132541</td>\n",
       "      <td>0.062047</td>\n",
       "      <td>-0.013972</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.080052</td>\n",
       "      <td>0.053115</td>\n",
       "      <td>0.061013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.607257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>465.47546</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001574</td>\n",
       "      <td>-0.003638</td>\n",
       "      <td>0.045010</td>\n",
       "      <td>-0.000607</td>\n",
       "      <td>-0.011502</td>\n",
       "      <td>-0.058853</td>\n",
       "      <td>0.097505</td>\n",
       "      <td>-0.074669</td>\n",
       "      <td>-0.094811</td>\n",
       "      <td>0.030829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.667295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.64200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-14.848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071761</td>\n",
       "      <td>0.031575</td>\n",
       "      <td>0.125182</td>\n",
       "      <td>-0.057137</td>\n",
       "      <td>0.066375</td>\n",
       "      <td>0.185097</td>\n",
       "      <td>-0.159673</td>\n",
       "      <td>-0.119745</td>\n",
       "      <td>0.121316</td>\n",
       "      <td>0.205905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.696161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.57669</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209.141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198271</td>\n",
       "      <td>-0.166541</td>\n",
       "      <td>-0.326754</td>\n",
       "      <td>-0.115222</td>\n",
       "      <td>0.017432</td>\n",
       "      <td>-0.058725</td>\n",
       "      <td>0.224419</td>\n",
       "      <td>0.217375</td>\n",
       "      <td>-0.128952</td>\n",
       "      <td>0.042131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.435684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370.02404</td>\n",
       "      <td>38.249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-13.538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>243.981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024623</td>\n",
       "      <td>0.026736</td>\n",
       "      <td>0.021689</td>\n",
       "      <td>-0.087088</td>\n",
       "      <td>-0.071128</td>\n",
       "      <td>0.028972</td>\n",
       "      <td>0.084496</td>\n",
       "      <td>-0.016510</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>-0.024705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.395608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>356.25751</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-11.893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.427447</td>\n",
       "      <td>94.557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067695</td>\n",
       "      <td>0.181081</td>\n",
       "      <td>-0.048400</td>\n",
       "      <td>-0.147695</td>\n",
       "      <td>0.168188</td>\n",
       "      <td>0.278875</td>\n",
       "      <td>-0.326459</td>\n",
       "      <td>-0.030446</td>\n",
       "      <td>0.031988</td>\n",
       "      <td>-0.156224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.445222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>241.16200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.638658</td>\n",
       "      <td>174.424</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068359</td>\n",
       "      <td>0.125031</td>\n",
       "      <td>-0.120150</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>-0.090095</td>\n",
       "      <td>-0.090097</td>\n",
       "      <td>-0.013552</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>0.043353</td>\n",
       "      <td>-0.176031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.516659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.82730</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-4.535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.637829</td>\n",
       "      <td>99.995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.008580</td>\n",
       "      <td>0.030726</td>\n",
       "      <td>-0.005150</td>\n",
       "      <td>-0.027171</td>\n",
       "      <td>0.020220</td>\n",
       "      <td>-0.023699</td>\n",
       "      <td>0.015442</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>-0.050775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.717210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.75791</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-7.174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.861</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014491</td>\n",
       "      <td>-0.029350</td>\n",
       "      <td>-0.107174</td>\n",
       "      <td>0.100396</td>\n",
       "      <td>0.150780</td>\n",
       "      <td>0.123939</td>\n",
       "      <td>0.025364</td>\n",
       "      <td>-0.122826</td>\n",
       "      <td>0.219687</td>\n",
       "      <td>-0.037529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.536351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.41098</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-5.011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.652878</td>\n",
       "      <td>142.069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258019</td>\n",
       "      <td>-0.091486</td>\n",
       "      <td>0.074762</td>\n",
       "      <td>0.131796</td>\n",
       "      <td>-0.120450</td>\n",
       "      <td>0.079083</td>\n",
       "      <td>0.220295</td>\n",
       "      <td>-0.110491</td>\n",
       "      <td>-0.007460</td>\n",
       "      <td>-0.103204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.257496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.38159</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-13.338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173833</td>\n",
       "      <td>-0.135618</td>\n",
       "      <td>-0.376822</td>\n",
       "      <td>-0.392072</td>\n",
       "      <td>0.097855</td>\n",
       "      <td>-0.493714</td>\n",
       "      <td>-0.216954</td>\n",
       "      <td>-0.027634</td>\n",
       "      <td>-0.098984</td>\n",
       "      <td>0.022526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.365026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.00771</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375984</td>\n",
       "      <td>108.292</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.405519</td>\n",
       "      <td>0.088365</td>\n",
       "      <td>-0.033198</td>\n",
       "      <td>-0.488178</td>\n",
       "      <td>0.115622</td>\n",
       "      <td>-0.116070</td>\n",
       "      <td>0.200145</td>\n",
       "      <td>0.166006</td>\n",
       "      <td>-0.123686</td>\n",
       "      <td>0.418106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.550991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.94240</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-5.542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.652359</td>\n",
       "      <td>212.293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092419</td>\n",
       "      <td>-0.022426</td>\n",
       "      <td>-0.009759</td>\n",
       "      <td>-0.121938</td>\n",
       "      <td>0.136994</td>\n",
       "      <td>0.028558</td>\n",
       "      <td>-0.154419</td>\n",
       "      <td>0.160171</td>\n",
       "      <td>-0.097439</td>\n",
       "      <td>-0.338712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>0.511526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.70322</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-15.838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.605246</td>\n",
       "      <td>116.239</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136567</td>\n",
       "      <td>-0.011174</td>\n",
       "      <td>-0.087017</td>\n",
       "      <td>-0.021760</td>\n",
       "      <td>-0.101368</td>\n",
       "      <td>0.019626</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>0.048106</td>\n",
       "      <td>0.058837</td>\n",
       "      <td>-0.016899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>0.395791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.28526</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.439</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049759</td>\n",
       "      <td>-0.004951</td>\n",
       "      <td>-0.134269</td>\n",
       "      <td>0.110048</td>\n",
       "      <td>-0.045112</td>\n",
       "      <td>-0.140278</td>\n",
       "      <td>-0.117643</td>\n",
       "      <td>-0.042859</td>\n",
       "      <td>-0.096953</td>\n",
       "      <td>0.031363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>0.570107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.15628</td>\n",
       "      <td>1.071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-8.959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156875</td>\n",
       "      <td>0.279641</td>\n",
       "      <td>-0.073200</td>\n",
       "      <td>0.156610</td>\n",
       "      <td>0.209493</td>\n",
       "      <td>0.017738</td>\n",
       "      <td>0.094391</td>\n",
       "      <td>-0.025249</td>\n",
       "      <td>0.359924</td>\n",
       "      <td>0.113922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>0.643072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.19873</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.737850</td>\n",
       "      <td>241.818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115165</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>0.023710</td>\n",
       "      <td>0.075277</td>\n",
       "      <td>0.082258</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.037546</td>\n",
       "      <td>-0.058450</td>\n",
       "      <td>0.052846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>0.417413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.67220</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-3.779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.653783</td>\n",
       "      <td>147.910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071536</td>\n",
       "      <td>0.133359</td>\n",
       "      <td>0.084083</td>\n",
       "      <td>-0.106744</td>\n",
       "      <td>0.046547</td>\n",
       "      <td>0.051405</td>\n",
       "      <td>0.084773</td>\n",
       "      <td>0.033311</td>\n",
       "      <td>0.149244</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>0.787005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301.19138</td>\n",
       "      <td>2.606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-7.488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679077</td>\n",
       "      <td>95.929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027345</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>-0.039256</td>\n",
       "      <td>0.125077</td>\n",
       "      <td>0.037324</td>\n",
       "      <td>-0.009988</td>\n",
       "      <td>-0.016277</td>\n",
       "      <td>-0.005696</td>\n",
       "      <td>-0.013787</td>\n",
       "      <td>0.012358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>0.410477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.90730</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-13.613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.604128</td>\n",
       "      <td>127.463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165175</td>\n",
       "      <td>-0.316569</td>\n",
       "      <td>0.313336</td>\n",
       "      <td>-0.081194</td>\n",
       "      <td>-0.244938</td>\n",
       "      <td>0.354851</td>\n",
       "      <td>-0.026896</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>-0.096471</td>\n",
       "      <td>-0.095536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>0.292663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.58077</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-7.910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234001</td>\n",
       "      <td>-0.122726</td>\n",
       "      <td>-0.185162</td>\n",
       "      <td>0.295596</td>\n",
       "      <td>-0.026165</td>\n",
       "      <td>-0.019064</td>\n",
       "      <td>0.285017</td>\n",
       "      <td>-0.185975</td>\n",
       "      <td>0.276857</td>\n",
       "      <td>-0.101484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>0.653513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.83628</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-11.949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071181</td>\n",
       "      <td>-0.053509</td>\n",
       "      <td>-0.117661</td>\n",
       "      <td>-0.023591</td>\n",
       "      <td>0.131442</td>\n",
       "      <td>-0.024724</td>\n",
       "      <td>0.053649</td>\n",
       "      <td>-0.068918</td>\n",
       "      <td>0.077415</td>\n",
       "      <td>-0.088986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>0.383394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.08689</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.324059</td>\n",
       "      <td>90.645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032159</td>\n",
       "      <td>0.156245</td>\n",
       "      <td>0.068414</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>-0.023748</td>\n",
       "      <td>0.098083</td>\n",
       "      <td>-0.063538</td>\n",
       "      <td>0.097458</td>\n",
       "      <td>-0.069640</td>\n",
       "      <td>-0.010831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>0.628246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.42567</td>\n",
       "      <td>1.127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215080</td>\n",
       "      <td>175.954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092932</td>\n",
       "      <td>0.101182</td>\n",
       "      <td>-0.239394</td>\n",
       "      <td>-0.130302</td>\n",
       "      <td>-0.060102</td>\n",
       "      <td>-0.165674</td>\n",
       "      <td>-0.144740</td>\n",
       "      <td>-0.216777</td>\n",
       "      <td>0.117264</td>\n",
       "      <td>-0.194880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>0.349476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.71791</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-5.281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.559647</td>\n",
       "      <td>123.998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018866</td>\n",
       "      <td>0.097093</td>\n",
       "      <td>-0.115221</td>\n",
       "      <td>0.016441</td>\n",
       "      <td>-0.099853</td>\n",
       "      <td>-0.115470</td>\n",
       "      <td>-0.009950</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.073552</td>\n",
       "      <td>0.265551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>0.317289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.19138</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-2.760</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086354</td>\n",
       "      <td>0.214460</td>\n",
       "      <td>0.010580</td>\n",
       "      <td>-0.031481</td>\n",
       "      <td>-0.057409</td>\n",
       "      <td>-0.100079</td>\n",
       "      <td>-0.037588</td>\n",
       "      <td>-0.092915</td>\n",
       "      <td>-0.121965</td>\n",
       "      <td>0.248668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.92281</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-9.093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644824</td>\n",
       "      <td>101.871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203388</td>\n",
       "      <td>0.047813</td>\n",
       "      <td>-0.184507</td>\n",
       "      <td>-0.017866</td>\n",
       "      <td>0.401238</td>\n",
       "      <td>-0.049714</td>\n",
       "      <td>-0.087597</td>\n",
       "      <td>-0.118565</td>\n",
       "      <td>0.219409</td>\n",
       "      <td>0.061213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>0.504308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.18567</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-3.565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.665160</td>\n",
       "      <td>151.184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041969</td>\n",
       "      <td>-0.025815</td>\n",
       "      <td>-0.032693</td>\n",
       "      <td>0.055438</td>\n",
       "      <td>0.007367</td>\n",
       "      <td>-0.054022</td>\n",
       "      <td>0.021562</td>\n",
       "      <td>0.035540</td>\n",
       "      <td>0.057047</td>\n",
       "      <td>0.034288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>0.547764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>266.47465</td>\n",
       "      <td>2.322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-3.952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.928617</td>\n",
       "      <td>112.486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099596</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>-0.118900</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>0.110857</td>\n",
       "      <td>-0.141050</td>\n",
       "      <td>0.124110</td>\n",
       "      <td>-0.010368</td>\n",
       "      <td>-0.067659</td>\n",
       "      <td>-0.121440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>0.386180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.43710</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-8.955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022137</td>\n",
       "      <td>0.185381</td>\n",
       "      <td>-0.136340</td>\n",
       "      <td>0.192709</td>\n",
       "      <td>-0.018945</td>\n",
       "      <td>-0.031252</td>\n",
       "      <td>0.099657</td>\n",
       "      <td>0.049196</td>\n",
       "      <td>-0.152634</td>\n",
       "      <td>0.144843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>0.458211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273.13587</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-7.387</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.386477</td>\n",
       "      <td>109.965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015174</td>\n",
       "      <td>0.114970</td>\n",
       "      <td>0.065712</td>\n",
       "      <td>0.061421</td>\n",
       "      <td>-0.073921</td>\n",
       "      <td>-0.000804</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>-0.103795</td>\n",
       "      <td>-0.109344</td>\n",
       "      <td>0.144944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>0.418990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.72444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-13.601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173046</td>\n",
       "      <td>0.018088</td>\n",
       "      <td>-0.064331</td>\n",
       "      <td>-0.036819</td>\n",
       "      <td>-0.111728</td>\n",
       "      <td>-0.043001</td>\n",
       "      <td>0.257973</td>\n",
       "      <td>-0.012162</td>\n",
       "      <td>0.056939</td>\n",
       "      <td>0.225762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>0.580013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304.14322</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.373</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.352232</td>\n",
       "      <td>133.193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041935</td>\n",
       "      <td>-0.001684</td>\n",
       "      <td>0.153186</td>\n",
       "      <td>0.106519</td>\n",
       "      <td>-0.016889</td>\n",
       "      <td>-0.143308</td>\n",
       "      <td>-0.104518</td>\n",
       "      <td>0.030803</td>\n",
       "      <td>0.052087</td>\n",
       "      <td>0.139842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>0.352976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.21098</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-10.416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017013</td>\n",
       "      <td>0.159850</td>\n",
       "      <td>-0.059139</td>\n",
       "      <td>0.357322</td>\n",
       "      <td>0.064763</td>\n",
       "      <td>0.314818</td>\n",
       "      <td>0.210523</td>\n",
       "      <td>-0.100162</td>\n",
       "      <td>0.112544</td>\n",
       "      <td>-0.075768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>0.307540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.41751</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473347</td>\n",
       "      <td>90.291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034197</td>\n",
       "      <td>0.134060</td>\n",
       "      <td>-0.116252</td>\n",
       "      <td>0.073133</td>\n",
       "      <td>-0.043545</td>\n",
       "      <td>-0.145367</td>\n",
       "      <td>0.012707</td>\n",
       "      <td>0.064558</td>\n",
       "      <td>0.059753</td>\n",
       "      <td>-0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>0.512197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>313.15546</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-3.528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.443291</td>\n",
       "      <td>98.927</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039902</td>\n",
       "      <td>0.058614</td>\n",
       "      <td>-0.099297</td>\n",
       "      <td>0.111421</td>\n",
       "      <td>0.169195</td>\n",
       "      <td>-0.165200</td>\n",
       "      <td>-0.008510</td>\n",
       "      <td>0.107266</td>\n",
       "      <td>-0.326524</td>\n",
       "      <td>-0.215702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>0.547507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.25016</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-13.770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.579039</td>\n",
       "      <td>207.238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355157</td>\n",
       "      <td>0.138950</td>\n",
       "      <td>0.318905</td>\n",
       "      <td>-0.033054</td>\n",
       "      <td>-0.121350</td>\n",
       "      <td>0.043618</td>\n",
       "      <td>-0.077167</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.125754</td>\n",
       "      <td>-0.047178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>0.462190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.19873</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.323</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.468998</td>\n",
       "      <td>95.264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>0.010232</td>\n",
       "      <td>-0.006489</td>\n",
       "      <td>-0.050188</td>\n",
       "      <td>-0.065936</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>-0.030919</td>\n",
       "      <td>0.023768</td>\n",
       "      <td>-0.017302</td>\n",
       "      <td>0.030279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>0.413255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.90077</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-17.548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327737</td>\n",
       "      <td>132.358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262093</td>\n",
       "      <td>0.136393</td>\n",
       "      <td>0.622580</td>\n",
       "      <td>-0.242330</td>\n",
       "      <td>0.099985</td>\n",
       "      <td>-0.165820</td>\n",
       "      <td>0.702081</td>\n",
       "      <td>0.241222</td>\n",
       "      <td>-0.145111</td>\n",
       "      <td>-0.249002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>0.384426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191.21587</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-6.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287492</td>\n",
       "      <td>0.165111</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>-0.100274</td>\n",
       "      <td>0.297340</td>\n",
       "      <td>0.211924</td>\n",
       "      <td>-0.444915</td>\n",
       "      <td>0.072321</td>\n",
       "      <td>0.106971</td>\n",
       "      <td>-0.124037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>0.438168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.86649</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-16.059</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021457</td>\n",
       "      <td>-0.040776</td>\n",
       "      <td>-0.111761</td>\n",
       "      <td>0.020623</td>\n",
       "      <td>0.194664</td>\n",
       "      <td>0.193310</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>-0.020111</td>\n",
       "      <td>-0.200433</td>\n",
       "      <td>0.092118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>0.345241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346.51383</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-5.802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.265861</td>\n",
       "      <td>88.344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059912</td>\n",
       "      <td>-0.084552</td>\n",
       "      <td>-0.282151</td>\n",
       "      <td>0.134663</td>\n",
       "      <td>0.046641</td>\n",
       "      <td>-0.051344</td>\n",
       "      <td>0.067716</td>\n",
       "      <td>0.239879</td>\n",
       "      <td>-0.169444</td>\n",
       "      <td>0.044690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>0.373750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243.17342</td>\n",
       "      <td>3.901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-11.996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.657733</td>\n",
       "      <td>160.089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013574</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>-0.021476</td>\n",
       "      <td>-0.003221</td>\n",
       "      <td>0.022712</td>\n",
       "      <td>0.014274</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>-0.029425</td>\n",
       "      <td>0.027915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2326 rows  661 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist_hotttnesss  danceability   duration  end_of_fade_in  energy  \\\n",
       "0              0.434860           0.0  252.99546           0.514     0.0   \n",
       "1              0.334520           0.0  163.63057           0.000     0.0   \n",
       "2              0.539245           0.0  216.84200           0.000     0.0   \n",
       "3              0.592439           0.0  218.90567           0.000     0.0   \n",
       "4              0.455559           0.0  283.48036           0.113     0.0   \n",
       "5              0.791143           0.0  208.95302           3.245     0.0   \n",
       "6              0.578302           0.0  154.93179           0.107     0.0   \n",
       "7              0.481656           0.0  199.96689           0.450     0.0   \n",
       "8              0.411546           0.0  319.84281           0.000     0.0   \n",
       "9              0.459660           0.0  258.16771           0.000     0.0   \n",
       "10             0.405178           0.0  461.71383           0.000     0.0   \n",
       "11             0.387912           0.0  253.90975           0.107     0.0   \n",
       "12             0.683658           0.0  237.21751           0.000     0.0   \n",
       "13             0.405967           0.0  186.20036           0.148     0.0   \n",
       "14             0.718891           0.0  311.27465           0.328     0.0   \n",
       "15             0.446072           0.0  286.58893           0.165     0.0   \n",
       "16             0.579989           0.0  324.23138          12.452     0.0   \n",
       "17             0.417413           0.0   92.76036           0.000     0.0   \n",
       "18             0.607257           0.0  465.47546           0.000     0.0   \n",
       "19             0.667295           0.0  229.64200           0.000     0.0   \n",
       "20             0.696161           0.0  181.57669           0.000     0.0   \n",
       "21             0.435684           0.0  370.02404          38.249     0.0   \n",
       "22             0.395608           0.0  356.25751           0.000     0.0   \n",
       "23             0.445222           0.0  241.16200           0.000     0.0   \n",
       "24             0.516659           0.0  250.82730           0.000     0.0   \n",
       "25             0.717210           0.0  231.75791           0.531     0.0   \n",
       "26             0.536351           0.0  264.41098           0.072     0.0   \n",
       "27             0.257496           0.0  140.38159           0.000     0.0   \n",
       "28             0.365026           0.0  230.00771           0.247     0.0   \n",
       "29             0.550991           0.0   85.94240           0.196     0.0   \n",
       "...                 ...           ...        ...             ...     ...   \n",
       "2296           0.511526           0.0  274.70322           0.000     0.0   \n",
       "2297           0.395791           0.0  146.28526           0.000     0.0   \n",
       "2298           0.570107           0.0  320.15628           1.071     0.0   \n",
       "2299           0.643072           0.0  236.19873           0.000     0.0   \n",
       "2300           0.417413           0.0  264.67220           0.000     0.0   \n",
       "2301           0.787005           0.0  301.19138           2.606     0.0   \n",
       "2302           0.410477           0.0  200.90730           0.000     0.0   \n",
       "2303           0.292663           0.0  216.58077           0.154     0.0   \n",
       "2304           0.653513           0.0  199.83628           0.000     0.0   \n",
       "2305           0.383394           0.0  173.08689           0.181     0.0   \n",
       "2306           0.628246           0.0  198.42567           1.127     0.0   \n",
       "2307           0.349476           0.0  240.71791           0.235     0.0   \n",
       "2308           0.317289           0.0  237.19138           0.000     0.0   \n",
       "2309           0.370629           0.0  237.92281           0.206     0.0   \n",
       "2310           0.504308           0.0   92.18567           0.000     0.0   \n",
       "2311           0.547764           0.0  266.47465           2.322     0.0   \n",
       "2312           0.386180           0.0  232.43710           0.000     0.0   \n",
       "2313           0.458211           0.0  273.13587           0.206     0.0   \n",
       "2314           0.418990           0.0  168.72444           0.000     0.0   \n",
       "2315           0.580013           0.0  304.14322           0.000     0.0   \n",
       "2316           0.352976           0.0  277.21098           0.160     0.0   \n",
       "2317           0.307540           0.0  224.41751           0.000     0.0   \n",
       "2318           0.512197           0.0  313.15546           0.479     0.0   \n",
       "2319           0.547507           0.0  133.25016           0.241     0.0   \n",
       "2320           0.462190           0.0  108.19873           0.121     0.0   \n",
       "2321           0.413255           0.0  112.90077           0.160     0.0   \n",
       "2322           0.384426           0.0  191.21587           0.000     0.0   \n",
       "2323           0.438168           0.0  138.86649           0.000     0.0   \n",
       "2324           0.345241           0.0  346.51383           0.235     0.0   \n",
       "2325           0.373750           0.0  243.17342           3.901     0.0   \n",
       "\n",
       "       key  loudness  mode  song_hotttnesss    tempo  ...       615       616  \\\n",
       "0      1.0   -11.061   0.0         0.475638   80.084  ...  0.071945 -0.257032   \n",
       "1      7.0    -5.795   1.0              NaN   77.150  ...  0.106758 -0.030016   \n",
       "2     10.0    -4.264   1.0         0.788388   92.897  ...  0.041058 -0.032635   \n",
       "3      0.0    -4.707   0.0         0.681092  157.715  ... -0.029487 -0.151878   \n",
       "4      0.0    -4.076   0.0         0.687874   84.992  ... -0.050722 -0.062439   \n",
       "5      4.0    -6.052   1.0         0.872229  105.095  ... -0.145900  0.100286   \n",
       "6      5.0   -15.433   0.0         0.596841  100.042  ...  0.136758  0.125596   \n",
       "7      5.0   -20.172   1.0              NaN  110.100  ...  0.046465  0.089363   \n",
       "8      3.0    -4.325   0.0         0.624834   92.971  ... -0.151781  0.191513   \n",
       "9     11.0    -5.193   1.0         0.427447  117.936  ...  0.098311  0.019971   \n",
       "10     1.0    -9.989   0.0              NaN  138.512  ... -0.094475  0.053965   \n",
       "11     9.0    -5.548   1.0         0.576400  136.945  ...  0.017765 -0.139854   \n",
       "12     1.0    -7.057   1.0         0.476435  188.910  ... -0.300609  0.270010   \n",
       "13     7.0   -13.845   1.0         0.299877  156.285  ...  0.077810  0.038889   \n",
       "14     1.0    -4.857   1.0              NaN  139.950  ... -0.099829  0.175729   \n",
       "15     9.0    -4.627   1.0         0.536789   97.265  ... -0.007088  0.132718   \n",
       "16     4.0    -9.057   0.0         0.685351   87.899  ...  0.286286  0.010979   \n",
       "17     4.0    -6.769   0.0         0.594359  163.086  ... -0.139836 -0.029471   \n",
       "18     1.0    -6.278   1.0              NaN  131.999  ... -0.001574 -0.003638   \n",
       "19     7.0   -14.848   1.0              NaN   74.576  ... -0.071761  0.031575   \n",
       "20     3.0    -3.696   0.0              NaN  209.141  ...  0.198271 -0.166541   \n",
       "21     5.0   -13.538   0.0              NaN  243.981  ...  0.024623  0.026736   \n",
       "22     7.0   -11.893   1.0         0.427447   94.557  ...  0.067695  0.181081   \n",
       "23     2.0    -5.056   1.0         0.638658  174.424  ... -0.068359  0.125031   \n",
       "24     7.0    -4.535   1.0         0.637829   99.995  ...  0.006593  0.008580   \n",
       "25     2.0    -7.174   1.0              NaN  123.861  ... -0.014491 -0.029350   \n",
       "26     9.0    -5.011   1.0         0.652878  142.069  ... -0.258019 -0.091486   \n",
       "27     2.0   -13.338   1.0              NaN  117.867  ...  0.173833 -0.135618   \n",
       "28    10.0    -6.564   0.0         0.375984  108.292  ... -0.405519  0.088365   \n",
       "29    11.0    -5.542   1.0         0.652359  212.293  ...  0.092419 -0.022426   \n",
       "...    ...       ...   ...              ...      ...  ...       ...       ...   \n",
       "2296   6.0   -15.838   1.0         0.605246  116.239  ... -0.136567 -0.011174   \n",
       "2297   0.0   -12.439   1.0              NaN  102.117  ...  0.049759 -0.004951   \n",
       "2298   4.0    -8.959   0.0              NaN  148.684  ... -0.156875  0.279641   \n",
       "2299   0.0   -15.967   1.0         0.737850  241.818  ... -0.115165  0.012706   \n",
       "2300  10.0    -3.779   0.0         0.653783  147.910  ... -0.071536  0.133359   \n",
       "2301   5.0    -7.488   0.0         0.679077   95.929  ...  0.027345  0.002246   \n",
       "2302   4.0   -13.613   1.0         0.604128  127.463  ...  0.165175 -0.316569   \n",
       "2303   2.0    -7.910   1.0              NaN  121.687  ...  0.234001 -0.122726   \n",
       "2304   6.0   -11.949   1.0              NaN   96.002  ...  0.071181 -0.053509   \n",
       "2305   4.0    -3.390   1.0         0.324059   90.645  ... -0.032159  0.156245   \n",
       "2306   4.0    -7.958   0.0         0.215080  175.954  ...  0.092932  0.101182   \n",
       "2307   8.0    -5.281   1.0         0.559647  123.998  ...  0.018866  0.097093   \n",
       "2308   7.0    -2.760   1.0              NaN   95.953  ...  0.086354  0.214460   \n",
       "2309   9.0    -9.093   1.0         0.644824  101.871  ... -0.203388  0.047813   \n",
       "2310   6.0    -3.565   0.0         0.665160  151.184  ...  0.041969 -0.025815   \n",
       "2311   6.0    -3.952   0.0         0.928617  112.486  ... -0.099596  0.075100   \n",
       "2312  11.0    -8.955   0.0              NaN  130.201  ... -0.022137  0.185381   \n",
       "2313   2.0    -7.387   1.0         0.386477  109.965  ... -0.015174  0.114970   \n",
       "2314   2.0   -13.601   1.0         0.000000   74.894  ... -0.173046  0.018088   \n",
       "2315   5.0    -6.373   1.0         0.352232  133.193  ...  0.041935 -0.001684   \n",
       "2316  10.0   -10.416   0.0              NaN  111.682  ...  0.017013  0.159850   \n",
       "2317   2.0    -5.879   0.0         0.473347   90.291  ... -0.034197  0.134060   \n",
       "2318  11.0    -3.528   1.0         0.443291   98.927  ... -0.039902  0.058614   \n",
       "2319  10.0   -13.770   0.0         0.579039  207.238  ...  0.355157  0.138950   \n",
       "2320   0.0   -13.323   1.0         0.468998   95.264  ...  0.010073  0.010232   \n",
       "2321   9.0   -17.548   0.0         0.327737  132.358  ...  0.262093  0.136393   \n",
       "2322   6.0    -6.025   0.0         0.000000  136.478  ... -0.287492  0.165111   \n",
       "2323   9.0   -16.059   1.0              NaN  104.284  ...  0.021457 -0.040776   \n",
       "2324   7.0    -5.802   1.0         0.265861   88.344  ... -0.059912 -0.084552   \n",
       "2325   8.0   -11.996   1.0         0.657733  160.089  ...  0.013574 -0.000163   \n",
       "\n",
       "           617       618       619       620       621       622       623  \\\n",
       "0    -0.196539  0.293499 -0.090210 -0.008033 -0.063375 -0.091004 -0.023878   \n",
       "1    -0.204888 -0.081121 -0.086589  0.024623  0.020169 -0.202278 -0.147184   \n",
       "2    -0.087466 -0.047189 -0.054714  0.040012 -0.166939  0.152990  0.318973   \n",
       "3     0.157312 -0.086829  0.024325  0.144210 -0.169575  0.266788  0.334551   \n",
       "4     0.067779 -0.073572 -0.116098  0.100691  0.049677  0.043782 -0.046400   \n",
       "5     0.000739  0.013310 -0.072774  0.088626  0.122783  0.183677 -0.259670   \n",
       "6    -0.089743  0.011098 -0.007018 -0.029027 -0.111789 -0.012239  0.004903   \n",
       "7     0.180623 -0.047567  0.139121 -0.042693 -0.115458  0.064821 -0.090276   \n",
       "8     0.166944  0.123518 -0.274576  0.077000  0.168240  0.077520 -0.122940   \n",
       "9    -0.108096 -0.147739 -0.129239 -0.021527 -0.209052 -0.185252 -0.074520   \n",
       "10   -0.033818 -0.077687 -0.319165 -0.032971  0.028166  0.079650  0.219870   \n",
       "11    0.175820 -0.058053  0.095490  0.234333  0.170369 -0.224653  0.005404   \n",
       "12    0.000302  0.095163  0.121558  0.195638 -0.283264 -0.110193  0.283781   \n",
       "13    0.119301  0.068917  0.030684  0.046892 -0.000976 -0.127559 -0.087777   \n",
       "14   -0.195131  0.220543 -0.027311  0.083499  0.254968 -0.269290 -0.458477   \n",
       "15    0.062078  0.110979 -0.004852 -0.088944 -0.118659  0.065909 -0.041021   \n",
       "16    0.161341 -0.149894 -0.093640  0.197458 -0.079653 -0.095868  0.160691   \n",
       "17   -0.012448 -0.132541  0.062047 -0.013972  0.008045  0.080052  0.053115   \n",
       "18    0.045010 -0.000607 -0.011502 -0.058853  0.097505 -0.074669 -0.094811   \n",
       "19    0.125182 -0.057137  0.066375  0.185097 -0.159673 -0.119745  0.121316   \n",
       "20   -0.326754 -0.115222  0.017432 -0.058725  0.224419  0.217375 -0.128952   \n",
       "21    0.021689 -0.087088 -0.071128  0.028972  0.084496 -0.016510  0.004685   \n",
       "22   -0.048400 -0.147695  0.168188  0.278875 -0.326459 -0.030446  0.031988   \n",
       "23   -0.120150  0.008701 -0.090095 -0.090097 -0.013552  0.075334  0.043353   \n",
       "24    0.030726 -0.005150 -0.027171  0.020220 -0.023699  0.015442  0.000851   \n",
       "25   -0.107174  0.100396  0.150780  0.123939  0.025364 -0.122826  0.219687   \n",
       "26    0.074762  0.131796 -0.120450  0.079083  0.220295 -0.110491 -0.007460   \n",
       "27   -0.376822 -0.392072  0.097855 -0.493714 -0.216954 -0.027634 -0.098984   \n",
       "28   -0.033198 -0.488178  0.115622 -0.116070  0.200145  0.166006 -0.123686   \n",
       "29   -0.009759 -0.121938  0.136994  0.028558 -0.154419  0.160171 -0.097439   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2296 -0.087017 -0.021760 -0.101368  0.019626  0.006852  0.048106  0.058837   \n",
       "2297 -0.134269  0.110048 -0.045112 -0.140278 -0.117643 -0.042859 -0.096953   \n",
       "2298 -0.073200  0.156610  0.209493  0.017738  0.094391 -0.025249  0.359924   \n",
       "2299  0.023710  0.075277  0.082258  0.001885  0.038453  0.037546 -0.058450   \n",
       "2300  0.084083 -0.106744  0.046547  0.051405  0.084773  0.033311  0.149244   \n",
       "2301 -0.039256  0.125077  0.037324 -0.009988 -0.016277 -0.005696 -0.013787   \n",
       "2302  0.313336 -0.081194 -0.244938  0.354851 -0.026896  0.027688 -0.096471   \n",
       "2303 -0.185162  0.295596 -0.026165 -0.019064  0.285017 -0.185975  0.276857   \n",
       "2304 -0.117661 -0.023591  0.131442 -0.024724  0.053649 -0.068918  0.077415   \n",
       "2305  0.068414  0.016478 -0.023748  0.098083 -0.063538  0.097458 -0.069640   \n",
       "2306 -0.239394 -0.130302 -0.060102 -0.165674 -0.144740 -0.216777  0.117264   \n",
       "2307 -0.115221  0.016441 -0.099853 -0.115470 -0.009950  0.002390  0.073552   \n",
       "2308  0.010580 -0.031481 -0.057409 -0.100079 -0.037588 -0.092915 -0.121965   \n",
       "2309 -0.184507 -0.017866  0.401238 -0.049714 -0.087597 -0.118565  0.219409   \n",
       "2310 -0.032693  0.055438  0.007367 -0.054022  0.021562  0.035540  0.057047   \n",
       "2311 -0.118900 -0.003980  0.110857 -0.141050  0.124110 -0.010368 -0.067659   \n",
       "2312 -0.136340  0.192709 -0.018945 -0.031252  0.099657  0.049196 -0.152634   \n",
       "2313  0.065712  0.061421 -0.073921 -0.000804  0.006367 -0.103795 -0.109344   \n",
       "2314 -0.064331 -0.036819 -0.111728 -0.043001  0.257973 -0.012162  0.056939   \n",
       "2315  0.153186  0.106519 -0.016889 -0.143308 -0.104518  0.030803  0.052087   \n",
       "2316 -0.059139  0.357322  0.064763  0.314818  0.210523 -0.100162  0.112544   \n",
       "2317 -0.116252  0.073133 -0.043545 -0.145367  0.012707  0.064558  0.059753   \n",
       "2318 -0.099297  0.111421  0.169195 -0.165200 -0.008510  0.107266 -0.326524   \n",
       "2319  0.318905 -0.033054 -0.121350  0.043618 -0.077167  0.072917  0.125754   \n",
       "2320 -0.006489 -0.050188 -0.065936  0.050279 -0.030919  0.023768 -0.017302   \n",
       "2321  0.622580 -0.242330  0.099985 -0.165820  0.702081  0.241222 -0.145111   \n",
       "2322  0.005849 -0.100274  0.297340  0.211924 -0.444915  0.072321  0.106971   \n",
       "2323 -0.111761  0.020623  0.194664  0.193310  0.001233 -0.020111 -0.200433   \n",
       "2324 -0.282151  0.134663  0.046641 -0.051344  0.067716  0.239879 -0.169444   \n",
       "2325  0.014747 -0.021476 -0.003221  0.022712  0.014274  0.011559 -0.029425   \n",
       "\n",
       "           624  \n",
       "0    -0.152406  \n",
       "1     0.137444  \n",
       "2    -0.200929  \n",
       "3     0.293172  \n",
       "4     0.104637  \n",
       "5    -0.108917  \n",
       "6    -0.090266  \n",
       "7    -0.035782  \n",
       "8    -0.146868  \n",
       "9     0.110015  \n",
       "10    0.121621  \n",
       "11   -0.122940  \n",
       "12   -0.111221  \n",
       "13    0.099649  \n",
       "14   -0.044848  \n",
       "15   -0.141186  \n",
       "16   -0.055320  \n",
       "17    0.061013  \n",
       "18    0.030829  \n",
       "19    0.205905  \n",
       "20    0.042131  \n",
       "21   -0.024705  \n",
       "22   -0.156224  \n",
       "23   -0.176031  \n",
       "24   -0.050775  \n",
       "25   -0.037529  \n",
       "26   -0.103204  \n",
       "27    0.022526  \n",
       "28    0.418106  \n",
       "29   -0.338712  \n",
       "...        ...  \n",
       "2296 -0.016899  \n",
       "2297  0.031363  \n",
       "2298  0.113922  \n",
       "2299  0.052846  \n",
       "2300  0.000247  \n",
       "2301  0.012358  \n",
       "2302 -0.095536  \n",
       "2303 -0.101484  \n",
       "2304 -0.088986  \n",
       "2305 -0.010831  \n",
       "2306 -0.194880  \n",
       "2307  0.265551  \n",
       "2308  0.248668  \n",
       "2309  0.061213  \n",
       "2310  0.034288  \n",
       "2311 -0.121440  \n",
       "2312  0.144843  \n",
       "2313  0.144944  \n",
       "2314  0.225762  \n",
       "2315  0.139842  \n",
       "2316 -0.075768  \n",
       "2317 -0.000495  \n",
       "2318 -0.215702  \n",
       "2319 -0.047178  \n",
       "2320  0.030279  \n",
       "2321 -0.249002  \n",
       "2322 -0.124037  \n",
       "2323  0.092118  \n",
       "2324  0.044690  \n",
       "2325  0.027915  \n",
       "\n",
       "[2326 rows x 661 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDataFrame = pd.concat([finalDataFrame, PCALyrics], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(finalDataFrame[\"danceability\"]!=0))\n",
    "print(np.sum(finalDataFrame[\"energy\"]!=0))\n",
    "#finalDataFrame[\"energy\"]\n",
    "finalDataFrame = finalDataFrame.drop([\"danceability\", \"energy\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "def getAffinityMatrix(coordinates, k = 7):\n",
    "    \"\"\"\n",
    "    Calculate affinity matrix based on input coordinates matrix and the numeber\n",
    "    of nearest neighbours.\n",
    "    \n",
    "    Apply local scaling based on the k nearest neighbour\n",
    "        References:\n",
    "    https://papers.nips.cc/paper/2619-self-tuning-spectral-clustering.pdf\n",
    "    \"\"\"\n",
    "    # calculate euclidian distance matrix\n",
    "    dists = squareform(pdist(coordinates)) \n",
    "    \n",
    "    # for each row, sort the distances ascendingly and take the index of the \n",
    "    #k-th position (nearest neighbour)\n",
    "    knn_distances = np.sort(dists, axis=0)[k]\n",
    "    knn_distances = knn_distances[np.newaxis].T\n",
    "    \n",
    "    # calculate sigma_i * sigma_j\n",
    "    local_scale = knn_distances.dot(knn_distances.T)\n",
    "\n",
    "    affinity_matrix = dists * dists\n",
    "    affinity_matrix = -affinity_matrix / local_scale\n",
    "    # divide square distance matrix by local scale\n",
    "    affinity_matrix[np.where(np.isnan(affinity_matrix))] = 0.0\n",
    "    # apply exponential\n",
    "    affinity_matrix = np.exp(affinity_matrix)\n",
    "    np.fill_diagonal(affinity_matrix, 0)\n",
    "    return affinity_matrix\n",
    "\n",
    "import scipy\n",
    "from scipy.sparse import csgraph\n",
    "from scipy.sparse.linalg import eigsh\n",
    "def eigenDecomposition(A, plot = True):\n",
    "    \"\"\"\n",
    "    :param A: Affinity matrix\n",
    "    :param plot: plots the sorted eigen values for visual inspection\n",
    "    :return A tuple containing:\n",
    "    - the optimal number of clusters by eigengap heuristic\n",
    "    - all eigen values\n",
    "    - all eigen vectors\n",
    "    \n",
    "    This method performs the eigen decomposition on a given affinity matrix,\n",
    "    following the steps recommended in the paper:\n",
    "    1. Construct the normalized affinity matrix: L = D1/2AD 1/2.\n",
    "    2. Find the eigenvalues and their associated eigen vectors\n",
    "    3. Identify the maximum gap which corresponds to the number of clusters\n",
    "    by eigengap heuristic\n",
    "    \n",
    "    References:\n",
    "    https://papers.nips.cc/paper/2619-self-tuning-spectral-clustering.pdf\n",
    "    http://www.kyb.mpg.de/fileadmin/user_upload/files/publications/attachments/Luxburg07_tutorial_4488%5b0%5d.pdf\n",
    "    \"\"\"\n",
    "    L = csgraph.laplacian(A, normed=True)\n",
    "    n_components = A.shape[0]\n",
    "    \n",
    "    # LM parameter : Eigenvalues with largest magnitude (eigs, eigsh), that is, largest eigenvalues in \n",
    "    # the euclidean norm of complex numbers.\n",
    "    eigenvalues, eigenvectors = eigsh(L, k=n_components, which=\"LM\", sigma=1.0, maxiter=5000)\n",
    "    \n",
    "    if plot:\n",
    "        plt.title('Largest eigen values of input matrix')\n",
    "        plt.scatter(np.arange(len(eigenvalues)), eigenvalues)\n",
    "        plt.grid()\n",
    "        \n",
    "    # Identify the optimal number of clusters as the index corresponding\n",
    "    # to the larger gap between eigen values\n",
    "    index_largest_gap = np.argmax(np.diff(eigenvalues))\n",
    "    nb_clusters = index_largest_gap + 1\n",
    "        \n",
    "    return nb_clusters, eigenvalues, eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "affinity_matrix = getAffinityMatrix(finalDataFrame.drop('year',axis=1), k = 10)\n",
    "k, _,  _ = eigenDecomposition(affinity_matrix)\n",
    "print(f'Optimal number of clusters {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMix1 = GaussianMixture(15, covariance_type='full')\n",
    "myMix2 = GaussianMixture(30, covariance_type='full')\n",
    "thePreds1 = myMix1.fit_predict(finalDataFrame.drop('year',axis=1))\n",
    "thePreds2 = myMix2.fit_predict(finalDataFrame.drop('year',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterDF1 = pd.DataFrame({\"cluster\": thePreds1, \"year\":finalDataFrame['year']})\n",
    "clusterDF2 = pd.DataFrame({\"cluster\": thePreds2, \"year\":finalDataFrame['year']})\n",
    "x_train_clust1, x_test_clust1, y_train_clust1, y_test_clust1 = train_test_split(clusterDF1.drop('year',axis=1), clusterDF1['year'], test_size=0.2)\n",
    "x_train_clust2, x_test_clust2, y_train_clust2, y_test_clust2 = train_test_split(clusterDF1.drop('year',axis=1), clusterDF1['year'], test_size=0.2)\n",
    "\n",
    "\n",
    "x_train_new, x_test_new, y_train_new, y_test_new = train_test_split(finalDataFrame.drop('year',axis=1), finalDataFrame['year'], test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig Lasso train:  118.38365463195076 Orig Lass test:  160.01664946876272\n",
      "15 Cluster Lasso train:  144.04490560627372 15 Cluster Lass test:  137.0874021101292\n",
      "Higher Cluster Lasso train:  140.51179324802763 Higher Cluster Lass test:  151.1895243984075\n",
      "New Lasso train:  119.46016530027815 New Lasso test:  92.02223887871465\n"
     ]
    }
   ],
   "source": [
    "clusterLasso = linear_model.Lasso(alpha=0.1)\n",
    "clusterLasso.fit(x_train_clust1, y_train_clust1)\n",
    "trainMSE_lasso_clust1 = mean_squared_error(y_train_clust1, clusterLasso.predict(x_train_clust1))\n",
    "testMSE_lasso_clust1 = mean_squared_error(y_test_clust1, clusterLasso.predict(x_test_clust1))\n",
    "\n",
    "trainMSE_lasso_clust2 = mean_squared_error(y_train_clust2, clusterLasso.predict(x_train_clust2))\n",
    "testMSE_lasso_clust2 = mean_squared_error(y_test_clust2, clusterLasso.predict(x_test_clust2))\n",
    "\n",
    "print(\"Orig Lasso train: \", trainMSE_lasso, \"Orig Lass test: \", testMSE_lasso)\n",
    "print(\"15 Cluster Lasso train: \", trainMSE_lasso_clust1, \"15 Cluster Lass test: \", testMSE_lasso_clust1)\n",
    "print(\"Higher Cluster Lasso train: \", trainMSE_lasso_clust2, \"Higher Cluster Lass test: \", testMSE_lasso_clust2)\n",
    "\n",
    "regLasso = linear_model.Lasso(alpha=0.1)\n",
    "regLasso.fit(x_train_new, y_train_new)\n",
    "trainMSE_lasso = mean_squared_error(y_train_new, regLasso.predict(x_train_new))\n",
    "testMSE_lasso = mean_squared_error(y_test_new, regLasso.predict(x_test_new))\n",
    "\n",
    "print(\"New Lasso train: \", trainMSE_lasso, \"New Lasso test: \", testMSE_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/175\n",
      "1860/1860 [==============================] - 0s 235us/step - loss: 3987844.9441\n",
      "Epoch 2/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 3986787.8790\n",
      "Epoch 3/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 3983188.2484\n",
      "Epoch 4/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 3974592.6989\n",
      "Epoch 5/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 3958560.0651\n",
      "Epoch 6/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 3932706.3849\n",
      "Epoch 7/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 3895449.1376\n",
      "Epoch 8/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 3844626.4699\n",
      "Epoch 9/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 3779401.5333\n",
      "Epoch 10/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 3698813.2140\n",
      "Epoch 11/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 3602516.6183\n",
      "Epoch 12/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 3490330.5860\n",
      "Epoch 13/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 3363612.7403\n",
      "Epoch 14/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 3222674.0129\n",
      "Epoch 15/175\n",
      "1860/1860 [==============================] - 0s 26us/step - loss: 3070812.2618\n",
      "Epoch 16/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 2909232.7344\n",
      "Epoch 17/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 2740518.2237\n",
      "Epoch 18/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 2569017.1871\n",
      "Epoch 19/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 2395977.6855\n",
      "Epoch 20/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 2225940.8925\n",
      "Epoch 21/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 2062580.3425\n",
      "Epoch 22/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 1907280.5683\n",
      "Epoch 23/175\n",
      "1860/1860 [==============================] - 0s 27us/step - loss: 1764043.9858\n",
      "Epoch 24/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 1634535.5194\n",
      "Epoch 25/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 1520118.2984\n",
      "Epoch 26/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 1422163.3978\n",
      "Epoch 27/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 1340095.7812\n",
      "Epoch 28/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 1273306.8546\n",
      "Epoch 29/175\n",
      "1860/1860 [==============================] - 0s 26us/step - loss: 1220594.1935\n",
      "Epoch 30/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 1179524.6930\n",
      "Epoch 31/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 1149266.2995\n",
      "Epoch 32/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 1126208.8040\n",
      "Epoch 33/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 1109351.7906\n",
      "Epoch 34/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 1096697.1793\n",
      "Epoch 35/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 1086908.5933\n",
      "Epoch 36/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 1078776.6108\n",
      "Epoch 37/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 1072075.0444\n",
      "Epoch 38/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 1065955.8890\n",
      "Epoch 39/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 1060132.7089\n",
      "Epoch 40/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 1054445.7530\n",
      "Epoch 41/175\n",
      "1860/1860 [==============================] - 0s 26us/step - loss: 1048847.0172\n",
      "Epoch 42/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 1043265.7960\n",
      "Epoch 43/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 1037680.7988\n",
      "Epoch 44/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 1031934.4966\n",
      "Epoch 45/175\n",
      "1860/1860 [==============================] - 0s 26us/step - loss: 1026133.5489\n",
      "Epoch 46/175\n",
      "1860/1860 [==============================] - 0s 26us/step - loss: 1020321.8156\n",
      "Epoch 47/175\n",
      "1860/1860 [==============================] - 0s 27us/step - loss: 1014179.2894\n",
      "Epoch 48/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 1008076.2941\n",
      "Epoch 49/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 1001835.9073\n",
      "Epoch 50/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 995420.4503\n",
      "Epoch 51/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 989086.6272\n",
      "Epoch 52/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 982457.5024\n",
      "Epoch 53/175\n",
      "1860/1860 [==============================] - 0s 26us/step - loss: 975703.5516\n",
      "Epoch 54/175\n",
      "1860/1860 [==============================] - 0s 26us/step - loss: 968789.1317\n",
      "Epoch 55/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 961814.8702\n",
      "Epoch 56/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 954741.4492\n",
      "Epoch 57/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 947486.1535\n",
      "Epoch 58/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 939910.5054\n",
      "Epoch 59/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 932376.5864\n",
      "Epoch 60/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 924685.4876\n",
      "Epoch 61/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 916851.4953\n",
      "Epoch 62/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 908802.6699\n",
      "Epoch 63/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 900493.8528\n",
      "Epoch 64/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 892121.0559\n",
      "Epoch 65/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 883618.2884\n",
      "Epoch 66/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 874639.3696\n",
      "Epoch 67/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 865705.7272\n",
      "Epoch 68/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 856632.3341\n",
      "Epoch 69/175\n",
      "1860/1860 [==============================] - 0s 26us/step - loss: 847372.4790\n",
      "Epoch 70/175\n",
      "1860/1860 [==============================] - 0s 26us/step - loss: 837714.9773\n",
      "Epoch 71/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 827866.9747\n",
      "Epoch 72/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 817857.7102\n",
      "Epoch 73/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 807677.5134\n",
      "Epoch 74/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 797099.7076\n",
      "Epoch 75/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 786309.4105\n",
      "Epoch 76/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 775212.6062\n",
      "Epoch 77/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 763866.3450\n",
      "Epoch 78/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 752385.2148\n",
      "Epoch 79/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 740257.6718\n",
      "Epoch 80/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 728121.2711\n",
      "Epoch 81/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 715822.9376\n",
      "Epoch 82/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 702918.4503\n",
      "Epoch 83/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 690041.2343\n",
      "Epoch 84/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 676740.0016\n",
      "Epoch 85/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 663093.9745\n",
      "Epoch 86/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 649078.2647\n",
      "Epoch 87/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 634835.6738\n",
      "Epoch 88/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 620273.7940\n",
      "Epoch 89/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 605473.0974\n",
      "Epoch 90/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 590029.0434\n",
      "Epoch 91/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 574457.8985\n",
      "Epoch 92/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 558633.0324\n",
      "Epoch 93/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 542402.6632\n",
      "Epoch 94/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 525751.6702\n",
      "Epoch 95/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 508832.0657\n",
      "Epoch 96/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 491495.6385\n",
      "Epoch 97/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 474011.5043\n",
      "Epoch 98/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 456380.6663\n",
      "Epoch 99/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 438597.8460\n",
      "Epoch 100/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 420791.9205\n",
      "Epoch 101/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 402680.3806\n",
      "Epoch 102/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 384449.4250\n",
      "Epoch 103/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 366061.1524\n",
      "Epoch 104/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 347584.0938\n",
      "Epoch 105/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 328939.3525\n",
      "Epoch 106/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 310287.4493\n",
      "Epoch 107/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 291938.5959\n",
      "Epoch 108/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 273806.0389\n",
      "Epoch 109/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 255712.9636\n",
      "Epoch 110/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 238077.1649\n",
      "Epoch 111/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 220717.3043\n",
      "Epoch 112/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 203657.0414\n",
      "Epoch 113/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 187291.1700\n",
      "Epoch 114/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 171411.1909\n",
      "Epoch 115/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 156078.1364\n",
      "Epoch 116/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 141243.7575\n",
      "Epoch 117/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 127161.2092\n",
      "Epoch 118/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 113838.2740\n",
      "Epoch 119/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 101466.4009\n",
      "Epoch 120/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 89790.2531\n",
      "Epoch 121/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 79007.4954\n",
      "Epoch 122/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 69085.4399\n",
      "Epoch 123/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 59941.8711\n",
      "Epoch 124/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 51692.5315\n",
      "Epoch 125/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 44192.0389\n",
      "Epoch 126/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 37494.6585\n",
      "Epoch 127/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 31619.5534\n",
      "Epoch 128/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 26361.2601\n",
      "Epoch 129/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 21848.7159\n",
      "Epoch 130/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 17952.3382\n",
      "Epoch 131/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 14622.1507\n",
      "Epoch 132/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 11792.0351\n",
      "Epoch 133/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 9416.5164\n",
      "Epoch 134/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 7457.4549\n",
      "Epoch 135/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 5860.0228\n",
      "Epoch 136/175\n",
      "1860/1860 [==============================] - 0s 23us/step - loss: 4555.4760\n",
      "Epoch 137/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 3518.1634\n",
      "Epoch 138/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 2691.4269\n",
      "Epoch 139/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 2052.3449\n",
      "Epoch 140/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 1556.9299\n",
      "Epoch 141/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 1178.4964\n",
      "Epoch 142/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 891.9766\n",
      "Epoch 143/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 677.9830\n",
      "Epoch 144/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 521.8390\n",
      "Epoch 145/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 407.6004\n",
      "Epoch 146/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 325.6740\n",
      "Epoch 147/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 267.2762\n",
      "Epoch 148/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 226.5509\n",
      "Epoch 149/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 198.5949\n",
      "Epoch 150/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 179.5889\n",
      "Epoch 151/175\n",
      "1860/1860 [==============================] - 0s 26us/step - loss: 167.0853\n",
      "Epoch 152/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 158.4736\n",
      "Epoch 153/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 153.1567\n",
      "Epoch 154/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 149.9375\n",
      "Epoch 155/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 147.4988\n",
      "Epoch 156/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 146.1203\n",
      "Epoch 157/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 145.5896\n",
      "Epoch 158/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 144.7993\n",
      "Epoch 159/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 144.6351\n",
      "Epoch 160/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 144.6362\n",
      "Epoch 161/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 144.3341\n",
      "Epoch 162/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 144.0592\n",
      "Epoch 163/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 144.6419\n",
      "Epoch 164/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 144.5121\n",
      "Epoch 165/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 144.1041\n",
      "Epoch 166/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 144.7544\n",
      "Epoch 167/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 144.5363\n",
      "Epoch 168/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 144.6401\n",
      "Epoch 169/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 144.3152\n",
      "Epoch 170/175\n",
      "1860/1860 [==============================] - 0s 26us/step - loss: 144.3907\n",
      "Epoch 171/175\n",
      "1860/1860 [==============================] - 0s 26us/step - loss: 144.3703\n",
      "Epoch 172/175\n",
      "1860/1860 [==============================] - 0s 26us/step - loss: 144.3551\n",
      "Epoch 173/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 144.1290\n",
      "Epoch 174/175\n",
      "1860/1860 [==============================] - 0s 24us/step - loss: 144.7303\n",
      "Epoch 175/175\n",
      "1860/1860 [==============================] - 0s 25us/step - loss: 144.4120\n",
      "144.06275110555592\n",
      "137.0941808156893\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "nFeat = x_train_clust1.shape[1]\n",
    "model.add(Dense(10, input_dim=nFeat, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(5, input_dim=nFeat, kernel_initializer='normal', activation='relu'))\n",
    "#model.add(Dense(1, input_dim=nFeat, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train_clust1, y_train_clust1, epochs=175, batch_size=32)\n",
    "print(mean_squared_error(y_train_clust1, model.predict(x_train_clust1)))\n",
    "print(mean_squared_error(y_test_clust1, model.predict(x_test_clust1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
