{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import scipy.io as sio\n",
    "import hdf5_getters\n",
    "from pandas import read_hdf\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalWorkingDF = pd.read_pickle(\"finalWorkingDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into training and testing set\n",
    "y = finalWorkingDF['year']\n",
    "x = finalWorkingDF.drop('year', axis = 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_pickle(\"XTrain\")\n",
    "y_train.to_pickle(\"YTrain\")\n",
    "x_test.to_pickle(\"XTest\")\n",
    "y_test.to_pickle(\"YTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainNumPy = x_train.to_numpy()\n",
    "x_testNumPy = x_test.to_numpy()\n",
    "y_trainNumPy = y_train.to_numpy()\n",
    "y_testNumPy = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### KNN CLASSIFIER ########################\n",
    "from sklearn.metrics import mean_squared_error\n",
    "n_neighbors = 15\n",
    "\n",
    "nnClassifier = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "nnClassifier.fit(x_trainNumPy, y_trainNumPy)\n",
    "\n",
    "# Get training and test predictions\n",
    "predictedtrainyears = nnClassifier.predict(x_trainNumPy)\n",
    "trainMSE = mean_squared_error(y_trainNumPy, predictedtrainyears)\n",
    "testMSE = mean_squared_error(y_testNumPy, nnClassifier.predict(x_testNumPy))\n",
    "# classifier_trainMSE = np.mean((nnClassifier.predict(x_trainNumPy) - y_trainNumPy)**2)\n",
    "# classifier_testMSE = np.mean((nnClassifier.predict(x_testNumPy) - y_testNumPy)**2)\n",
    "\n",
    "print(\"training MSE\", trainMSE)\n",
    "print(\"testing MSE\", testMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### KNN REGRESSION ########################\n",
    "n_neighbors = 15\n",
    "\n",
    "nnRegressor = neighbors.KNeighborsRegressor(n_neighbors)\n",
    "nnRegressor.fit(x_trainNumPy, y_trainNumPy)\n",
    "\n",
    "# Get training and test predictions\n",
    "predictedtrainyears = nnRegressor.predict(x_trainNumPy)\n",
    "trainMSE = mean_squared_error(y_trainNumPy, predictedtrainyears)\n",
    "testMSE = mean_squared_error(y_testNumPy, nnRegressor.predict(x_testNumPy))\n",
    "\n",
    "print(\"training MSE\", trainMSE)\n",
    "print(\"testing MSE\", testMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### NEURAL NETWORK ########################\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(3744,37), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x_trainNumPy, y_trainNumPy, epochs=150, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "train_scores = model.evaluate(x_trainNumPy, y_trainNumPy)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], train_scores[1]*100))\n",
    "test_scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], test_scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10-701 Song Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "For this project, we are exploring the question of whether different data sets about songs can predict the year of the songs' origin equally well. In particular we are looking at the 10,000 song subset of the million song dataset and the musixmatch dataset for the 10,000 song subset. The 10,000 song subset contains very detailed information about each song such as timbre and pitch vectors for each segment of the song, tatums, loudness and various other algorithmically determined factors such as artist hotness, song hotness, danceability, etc. In contrast, the musixmatch dataset only contains bag-of-words lyrics for each song. Our goal is to determine whether models predicting a song's release year trained on the musixmatch dataset can exhibit similar testing performance as models trained on the full feature-set of the 10k subset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
